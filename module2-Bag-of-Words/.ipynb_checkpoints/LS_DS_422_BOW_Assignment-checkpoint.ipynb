{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 159
    },
    "colab_type": "code",
    "id": "hyj-f9FDcVFp",
    "outputId": "5dd045fe-6e4c-458c-e2fc-253c3da9c805"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: nltk in /anaconda3/lib/python3.6/site-packages (3.4)\n",
      "Requirement already satisfied, skipping upgrade: six in /anaconda3/lib/python3.6/site-packages (from nltk) (1.12.0)\n",
      "Requirement already satisfied, skipping upgrade: singledispatch in /anaconda3/lib/python3.6/site-packages (from nltk) (3.4.0.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/danielleromanoff/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/danielleromanoff/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "!pip install -U nltk\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import sent_tokenize # Sentence Tokenizer\n",
    "from nltk.tokenize import word_tokenize # Word Tokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M7bcmqfGXrFG"
   },
   "source": [
    "# 1) (optional) Scrape 100 Job Listings that contain the title \"Data Scientist\" from indeed.com\n",
    "\n",
    "At a minimum your final dataframe of job listings should contain\n",
    "- Job Title\n",
    "- Job Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KcYlc1URXhlC"
   },
   "outputs": [],
   "source": [
    "# Additional Imports for scraping Indeed\n",
    "\n",
    "import requests\n",
    "import time\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting search results from indeed\n",
    "\n",
    "url = 'https://www.indeed.com/jobs?as_and=data+scientist&as_phr=&as_any=&as_not=&as_ttl=&as_cmp=&jt=all&st=&as_src=&salary=&radius=25&l=New+Jersey&fromage=any&limit=50&sort=&psf=advsrch#'\n",
    "page = requests.get(url)\n",
    "page = page.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n                            Implement field and office data collection efforts, data validation, and data evaluation. Process data, and oversee the development of map figures, data tables,...',\n",
       " \"\\n                            Previous internship or relevant work experiences in scripting, software development, or data analytics. In Global Data, we're responsible for delivering this...\",\n",
       " '\\n                            Junior Research Scientist*. At Rocky Mountain Scientific Laboratory, we associate peace with strength, courage, and action....',\n",
       " '\\n                            Candidate MUST live in NJ, Philadelphia PA area or NYC area. Position will include assisting with the research, data collection and reporting for Phase I...',\n",
       " '\\n                            Communication and presentation to external clients with relevance to the market and consumer insights. Consistently meets agreed upon project objectives....',\n",
       " '\\n                            Leveraging your educational background in Science, Mathematics, Statistics, Computer Science, Data Science, or a related discipline, along with your relevant...',\n",
       " '\\n                            Ensure complete accuracy, appropriate and consistent grammar, spelling, and punctuation on all reports and data collections....',\n",
       " '\\n                            Proficient with the use of advanced statistical analysis software and applications (SAS, R, SQL programming, etc.)....',\n",
       " '\\n            The Data Scientist Associate/Qlik Sense Developer role is responsible for modeling complex Institute problems, discovering Institute insights and identifying...',\n",
       " '\\nData scientists must be able to discuss their research in any level of detail with their peers, and with appropriate calibration to stakeholders in small and...',\n",
       " '\\n            Experience with one or more statistical or machine learning software such as R, Python,\". Background in applied statistical modeling on large experimental or...',\n",
       " '\\n            Machine Learning Engineer will be responsible for advocating, educating and ensuring that machine learning (ML) teams across the enterprise are following best...',\n",
       " '\\n            Design, develop, test, and document predictive, classifier, and deep learning machine learning AI models. Some exposure to SQL server Machine Learning technics....',\n",
       " '\\n            Performs data analytics, specifically data clean-up, data processing, predictive modeling, chemometric statistical modeling and analysis, multivariate data...',\n",
       " '\\n            Proficient with the use of advanced statistical analysis software and applications (SAS, R, SQL programming, etc.)....',\n",
       " '\\n            Develop and implement machine learning and optimization algorithms across multiple platforms to create scalable solutions with actionable insights from complex...',\n",
       " '\\n            Minimum of 2 years experience applying machine learning algorithms and data mining approaches in an applied setting is required....',\n",
       " '\\nData Curation Scientists are expected to perform analyses that require a high-level understanding of the biomedical scientific literature and experimental...',\n",
       " '\\n            Manages full data portfolio of spend area working with the various spend area data owners ensuring data accuracy and validity....',\n",
       " '\\n            Ensures maintenance of continuous cGMP compliance in day to day Stability Operations by themselves and others below their level such as Associates Scientists....',\n",
       " '\\n            The Data Scientist role is responsible for designing and implementing analytical tools and predictive models based on that intelligence, creating efficiencies...',\n",
       " '\\nData Analytics, Machine Learning or equivalent experience. This position is for a Data Scientist who can think strategically and intuitively about uses of data...',\n",
       " '\\n            Be a subject matter expert on machine learning and predictive modeling and a mentor to junior data scientists....',\n",
       " '\\n            Work with data architects to ensure that Big Data solutions are aligned with company-wide technology directions....',\n",
       " '\\n            New Jersey’s academic health center, Rutgers Biomedical and Health Sciences (RBHS) takes an integrated approach to educating students, providing clinical care,...',\n",
       " '\\n            Strong predictive data modeling experience is required with proven application in applying Decision Trees, Regression analysis, Neural Networks, Clustering, and...',\n",
       " '\\n            The Data Scientist will be part of the Data Science & Analytics team within our Product Marketing department. Strong working knowledge of data mining algorithms...',\n",
       " '\\n            Hadoop) in big data and advanced analytics. Develop powerful business insights from social, marketing and industrial data using advanced....',\n",
       " '\\n            Minimum 8 years of continuous and latest experience in data analytics, management, statistical analysis, quantitative analytics, and/or forecasting/predictive...',\n",
       " '\\n            Evaluate the stability data and trends. We are looking for an analytical scientist who has microbiology education background and has knowledge of...',\n",
       " '\\n            Must be able to write SQL queries and must have experience with data extraction. We have a client that is looking for a data scientist to add to its team....',\n",
       " '\\n            Leveraging the latest technologies in big data, machine learning and data mining, Spirent provides state-of-the-art software products for communication service...',\n",
       " '\\n            Support the Director, Data Science and Evaluation Research, and the SVP of Public Health and Inclusion in developing and implementing Autism Speaks’ public...',\n",
       " '\\n            Stay current on new trends in revenue management, machine learning, and advanced analytics through reviews of academic and practitioner literature....',\n",
       " '\\n            We are looking for an exceptional data scientists with a passion for using data to discover insights and utilize them to drive decision-making....',\n",
       " '\\n            Advanced Analytics - Data Scientists. Data Scientist II. Design, deploy and maintain statistical, predictive and data mining models to translate data into...',\n",
       " '\\n            This group is responsible for the data ecosystem that runs our businesses with teams that ensure our data is accurate, timely and has the proper risk controls...',\n",
       " '\\n            Preparation clinical pharmacology data analysis plans, tables, figures and listings for inclusion in clinical reports....',\n",
       " '\\n            HR Data & Analytics team seeks an expert in data analysis (including data structuring, mining, modeling, and visualization) with strong project management...',\n",
       " '\\n            As a Senior Data Scientist, you’ll lead projects that develop and perform complex analyses using Big Data technologies....',\n",
       " '\\n            Train subject matter experts in basic data science skills and increase organizational awareness about data analytics through engagement programs....',\n",
       " '\\n            Strong health care data knowledge (medical claims data, clinical data, pharmacy data, and eligibility data) preferred....',\n",
       " '\\nData scientists lead data processing and analysis tasks, such as monitoring data quality, developing documentation, applying statistical and data science...',\n",
       " '\\n            Scientific, engineering and practical knowledge of techniques and procedures applied to environmental compliance and/or waste management applicable to a wide...',\n",
       " '\\n            Maintains scientific curiosity, rigor, and documentation. Competency to manage moderate level of technical complexity, execute rapid and iterative development...',\n",
       " '\\n            for data analysis testing purpose Job Type: Temporary Salary: $10.00 to $11.00 ...',\n",
       " '\\n            Professional experience applying advanced analytics and data mining techniques to enable decision support systems and customer strategies....',\n",
       " '\\n            Scientific, engineering and practical knowledge of techniques and procedures applied to environmental compliance and/or waste management applicable to a wide...',\n",
       " '\\n            Peer Review of Data of other scientist and sterility technicians. Generating Quality Data Trend Reports. Working knowledge of data collection and/or spreadsheet...',\n",
       " '\\n            Strong health care data knowledge (medical claims data, clinical data, pharmacy data, and eligibility data) preferred....',\n",
       " '\\n            Ensure complete accuracy, appropriate and consistent grammar, spelling, and punctuation on all reports and data collections....',\n",
       " '\\n            The role Senior Data Scientist will be responsible for organizing, mining and visualizing complex R&D data to deliver new insights to enable rapid, high quality...',\n",
       " '\\n            Candidate MUST live in NJ, Philadelphia PA area or NYC area. Position will include assisting with the research, data collection and reporting for Phase I...',\n",
       " '\\n            Must be agile to grow in new directions, acquire new skills, and work with a team of scientists and practitioners from different functional areas to solve...',\n",
       " '\\n            Strong proven understanding of machine learning methods and applied statistical packages as applied to data analysis within open source scripting languages (e.g...',\n",
       " '\\n            Be a subject matter expert on machine learning and predictive modeling and a mentor to junior data scientists....',\n",
       " '\\n            Communication and presentation to external clients with relevance to the market and consumer insights. Consistently meets agreed upon project objectives....',\n",
       " '\\n            Leveraging your educational background in Science, Mathematics, Statistics, Computer Science, Data Science, or a related discipline, along with your relevant...']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup = BeautifulSoup(page, 'html.parser')\n",
    "listings = ([s.text for s in soup.findAll(class_='summary')])\n",
    "listings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Implement',\n",
       "  'field',\n",
       "  'and',\n",
       "  'office',\n",
       "  'data',\n",
       "  'collection',\n",
       "  'efforts',\n",
       "  'data',\n",
       "  'validation',\n",
       "  'and',\n",
       "  'data',\n",
       "  'evaluation',\n",
       "  'Process',\n",
       "  'data',\n",
       "  'and',\n",
       "  'oversee',\n",
       "  'the',\n",
       "  'development',\n",
       "  'of',\n",
       "  'map',\n",
       "  'figures',\n",
       "  'data',\n",
       "  'tables'],\n",
       " ['Previous',\n",
       "  'internship',\n",
       "  'or',\n",
       "  'relevant',\n",
       "  'work',\n",
       "  'experiences',\n",
       "  'in',\n",
       "  'scripting',\n",
       "  'software',\n",
       "  'development',\n",
       "  'or',\n",
       "  'data',\n",
       "  'analytics',\n",
       "  'In',\n",
       "  'Global',\n",
       "  'Data',\n",
       "  'were',\n",
       "  'responsible',\n",
       "  'for',\n",
       "  'delivering',\n",
       "  'this'],\n",
       " ['Junior',\n",
       "  'Research',\n",
       "  'Scientist',\n",
       "  'At',\n",
       "  'Rocky',\n",
       "  'Mountain',\n",
       "  'Scientific',\n",
       "  'Laboratory',\n",
       "  'we',\n",
       "  'associate',\n",
       "  'peace',\n",
       "  'with',\n",
       "  'strength',\n",
       "  'courage',\n",
       "  'and',\n",
       "  'action'],\n",
       " ['Candidate',\n",
       "  'MUST',\n",
       "  'live',\n",
       "  'in',\n",
       "  'NJ',\n",
       "  'Philadelphia',\n",
       "  'PA',\n",
       "  'area',\n",
       "  'or',\n",
       "  'NYC',\n",
       "  'area',\n",
       "  'Position',\n",
       "  'will',\n",
       "  'include',\n",
       "  'assisting',\n",
       "  'with',\n",
       "  'the',\n",
       "  'research',\n",
       "  'data',\n",
       "  'collection',\n",
       "  'and',\n",
       "  'reporting',\n",
       "  'for',\n",
       "  'Phase',\n",
       "  'I'],\n",
       " ['Communication',\n",
       "  'and',\n",
       "  'presentation',\n",
       "  'to',\n",
       "  'external',\n",
       "  'clients',\n",
       "  'with',\n",
       "  'relevance',\n",
       "  'to',\n",
       "  'the',\n",
       "  'market',\n",
       "  'and',\n",
       "  'consumer',\n",
       "  'insights',\n",
       "  'Consistently',\n",
       "  'meets',\n",
       "  'agreed',\n",
       "  'upon',\n",
       "  'project',\n",
       "  'objectives'],\n",
       " ['Leveraging',\n",
       "  'your',\n",
       "  'educational',\n",
       "  'background',\n",
       "  'in',\n",
       "  'Science',\n",
       "  'Mathematics',\n",
       "  'Statistics',\n",
       "  'Computer',\n",
       "  'Science',\n",
       "  'Data',\n",
       "  'Science',\n",
       "  'or',\n",
       "  'a',\n",
       "  'related',\n",
       "  'discipline',\n",
       "  'along',\n",
       "  'with',\n",
       "  'your',\n",
       "  'relevant'],\n",
       " ['Ensure',\n",
       "  'complete',\n",
       "  'accuracy',\n",
       "  'appropriate',\n",
       "  'and',\n",
       "  'consistent',\n",
       "  'grammar',\n",
       "  'spelling',\n",
       "  'and',\n",
       "  'punctuation',\n",
       "  'on',\n",
       "  'all',\n",
       "  'reports',\n",
       "  'and',\n",
       "  'data',\n",
       "  'collections'],\n",
       " ['Proficient',\n",
       "  'with',\n",
       "  'the',\n",
       "  'use',\n",
       "  'of',\n",
       "  'advanced',\n",
       "  'statistical',\n",
       "  'analysis',\n",
       "  'software',\n",
       "  'and',\n",
       "  'applications',\n",
       "  'SAS',\n",
       "  'R',\n",
       "  'SQL',\n",
       "  'programming',\n",
       "  'etc'],\n",
       " ['The',\n",
       "  'Data',\n",
       "  'Scientist',\n",
       "  'AssociateQlik',\n",
       "  'Sense',\n",
       "  'Developer',\n",
       "  'role',\n",
       "  'is',\n",
       "  'responsible',\n",
       "  'for',\n",
       "  'modeling',\n",
       "  'complex',\n",
       "  'Institute',\n",
       "  'problems',\n",
       "  'discovering',\n",
       "  'Institute',\n",
       "  'insights',\n",
       "  'and',\n",
       "  'identifying'],\n",
       " ['Data',\n",
       "  'scientists',\n",
       "  'must',\n",
       "  'be',\n",
       "  'able',\n",
       "  'to',\n",
       "  'discuss',\n",
       "  'their',\n",
       "  'research',\n",
       "  'in',\n",
       "  'any',\n",
       "  'level',\n",
       "  'of',\n",
       "  'detail',\n",
       "  'with',\n",
       "  'their',\n",
       "  'peers',\n",
       "  'and',\n",
       "  'with',\n",
       "  'appropriate',\n",
       "  'calibration',\n",
       "  'to',\n",
       "  'stakeholders',\n",
       "  'in',\n",
       "  'small',\n",
       "  'and'],\n",
       " ['Experience',\n",
       "  'with',\n",
       "  'one',\n",
       "  'or',\n",
       "  'more',\n",
       "  'statistical',\n",
       "  'or',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'software',\n",
       "  'such',\n",
       "  'as',\n",
       "  'R',\n",
       "  'Python',\n",
       "  'Background',\n",
       "  'in',\n",
       "  'applied',\n",
       "  'statistical',\n",
       "  'modeling',\n",
       "  'on',\n",
       "  'large',\n",
       "  'experimental',\n",
       "  'or'],\n",
       " ['Machine',\n",
       "  'Learning',\n",
       "  'Engineer',\n",
       "  'will',\n",
       "  'be',\n",
       "  'responsible',\n",
       "  'for',\n",
       "  'advocating',\n",
       "  'educating',\n",
       "  'and',\n",
       "  'ensuring',\n",
       "  'that',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'ML',\n",
       "  'teams',\n",
       "  'across',\n",
       "  'the',\n",
       "  'enterprise',\n",
       "  'are',\n",
       "  'following',\n",
       "  'best'],\n",
       " ['Design',\n",
       "  'develop',\n",
       "  'test',\n",
       "  'and',\n",
       "  'document',\n",
       "  'predictive',\n",
       "  'classifier',\n",
       "  'and',\n",
       "  'deep',\n",
       "  'learning',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'AI',\n",
       "  'models',\n",
       "  'Some',\n",
       "  'exposure',\n",
       "  'to',\n",
       "  'SQL',\n",
       "  'server',\n",
       "  'Machine',\n",
       "  'Learning',\n",
       "  'technics'],\n",
       " ['Performs',\n",
       "  'data',\n",
       "  'analytics',\n",
       "  'specifically',\n",
       "  'data',\n",
       "  'cleanup',\n",
       "  'data',\n",
       "  'processing',\n",
       "  'predictive',\n",
       "  'modeling',\n",
       "  'chemometric',\n",
       "  'statistical',\n",
       "  'modeling',\n",
       "  'and',\n",
       "  'analysis',\n",
       "  'multivariate',\n",
       "  'data'],\n",
       " ['Proficient',\n",
       "  'with',\n",
       "  'the',\n",
       "  'use',\n",
       "  'of',\n",
       "  'advanced',\n",
       "  'statistical',\n",
       "  'analysis',\n",
       "  'software',\n",
       "  'and',\n",
       "  'applications',\n",
       "  'SAS',\n",
       "  'R',\n",
       "  'SQL',\n",
       "  'programming',\n",
       "  'etc'],\n",
       " ['Develop',\n",
       "  'and',\n",
       "  'implement',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'and',\n",
       "  'optimization',\n",
       "  'algorithms',\n",
       "  'across',\n",
       "  'multiple',\n",
       "  'platforms',\n",
       "  'to',\n",
       "  'create',\n",
       "  'scalable',\n",
       "  'solutions',\n",
       "  'with',\n",
       "  'actionable',\n",
       "  'insights',\n",
       "  'from',\n",
       "  'complex'],\n",
       " ['Minimum',\n",
       "  'of',\n",
       "  '2',\n",
       "  'years',\n",
       "  'experience',\n",
       "  'applying',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'algorithms',\n",
       "  'and',\n",
       "  'data',\n",
       "  'mining',\n",
       "  'approaches',\n",
       "  'in',\n",
       "  'an',\n",
       "  'applied',\n",
       "  'setting',\n",
       "  'is',\n",
       "  'required'],\n",
       " ['Data',\n",
       "  'Curation',\n",
       "  'Scientists',\n",
       "  'are',\n",
       "  'expected',\n",
       "  'to',\n",
       "  'perform',\n",
       "  'analyses',\n",
       "  'that',\n",
       "  'require',\n",
       "  'a',\n",
       "  'highlevel',\n",
       "  'understanding',\n",
       "  'of',\n",
       "  'the',\n",
       "  'biomedical',\n",
       "  'scientific',\n",
       "  'literature',\n",
       "  'and',\n",
       "  'experimental'],\n",
       " ['Manages',\n",
       "  'full',\n",
       "  'data',\n",
       "  'portfolio',\n",
       "  'of',\n",
       "  'spend',\n",
       "  'area',\n",
       "  'working',\n",
       "  'with',\n",
       "  'the',\n",
       "  'various',\n",
       "  'spend',\n",
       "  'area',\n",
       "  'data',\n",
       "  'owners',\n",
       "  'ensuring',\n",
       "  'data',\n",
       "  'accuracy',\n",
       "  'and',\n",
       "  'validity'],\n",
       " ['Ensures',\n",
       "  'maintenance',\n",
       "  'of',\n",
       "  'continuous',\n",
       "  'cGMP',\n",
       "  'compliance',\n",
       "  'in',\n",
       "  'day',\n",
       "  'to',\n",
       "  'day',\n",
       "  'Stability',\n",
       "  'Operations',\n",
       "  'by',\n",
       "  'themselves',\n",
       "  'and',\n",
       "  'others',\n",
       "  'below',\n",
       "  'their',\n",
       "  'level',\n",
       "  'such',\n",
       "  'as',\n",
       "  'Associates',\n",
       "  'Scientists'],\n",
       " ['The',\n",
       "  'Data',\n",
       "  'Scientist',\n",
       "  'role',\n",
       "  'is',\n",
       "  'responsible',\n",
       "  'for',\n",
       "  'designing',\n",
       "  'and',\n",
       "  'implementing',\n",
       "  'analytical',\n",
       "  'tools',\n",
       "  'and',\n",
       "  'predictive',\n",
       "  'models',\n",
       "  'based',\n",
       "  'on',\n",
       "  'that',\n",
       "  'intelligence',\n",
       "  'creating',\n",
       "  'efficiencies'],\n",
       " ['Data',\n",
       "  'Analytics',\n",
       "  'Machine',\n",
       "  'Learning',\n",
       "  'or',\n",
       "  'equivalent',\n",
       "  'experience',\n",
       "  'This',\n",
       "  'position',\n",
       "  'is',\n",
       "  'for',\n",
       "  'a',\n",
       "  'Data',\n",
       "  'Scientist',\n",
       "  'who',\n",
       "  'can',\n",
       "  'think',\n",
       "  'strategically',\n",
       "  'and',\n",
       "  'intuitively',\n",
       "  'about',\n",
       "  'uses',\n",
       "  'of',\n",
       "  'data'],\n",
       " ['Be',\n",
       "  'a',\n",
       "  'subject',\n",
       "  'matter',\n",
       "  'expert',\n",
       "  'on',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'and',\n",
       "  'predictive',\n",
       "  'modeling',\n",
       "  'and',\n",
       "  'a',\n",
       "  'mentor',\n",
       "  'to',\n",
       "  'junior',\n",
       "  'data',\n",
       "  'scientists'],\n",
       " ['Work',\n",
       "  'with',\n",
       "  'data',\n",
       "  'architects',\n",
       "  'to',\n",
       "  'ensure',\n",
       "  'that',\n",
       "  'Big',\n",
       "  'Data',\n",
       "  'solutions',\n",
       "  'are',\n",
       "  'aligned',\n",
       "  'with',\n",
       "  'companywide',\n",
       "  'technology',\n",
       "  'directions'],\n",
       " ['New',\n",
       "  'Jersey',\n",
       "  '’',\n",
       "  's',\n",
       "  'academic',\n",
       "  'health',\n",
       "  'center',\n",
       "  'Rutgers',\n",
       "  'Biomedical',\n",
       "  'and',\n",
       "  'Health',\n",
       "  'Sciences',\n",
       "  'RBHS',\n",
       "  'takes',\n",
       "  'an',\n",
       "  'integrated',\n",
       "  'approach',\n",
       "  'to',\n",
       "  'educating',\n",
       "  'students',\n",
       "  'providing',\n",
       "  'clinical',\n",
       "  'care'],\n",
       " ['Strong',\n",
       "  'predictive',\n",
       "  'data',\n",
       "  'modeling',\n",
       "  'experience',\n",
       "  'is',\n",
       "  'required',\n",
       "  'with',\n",
       "  'proven',\n",
       "  'application',\n",
       "  'in',\n",
       "  'applying',\n",
       "  'Decision',\n",
       "  'Trees',\n",
       "  'Regression',\n",
       "  'analysis',\n",
       "  'Neural',\n",
       "  'Networks',\n",
       "  'Clustering',\n",
       "  'and'],\n",
       " ['The',\n",
       "  'Data',\n",
       "  'Scientist',\n",
       "  'will',\n",
       "  'be',\n",
       "  'part',\n",
       "  'of',\n",
       "  'the',\n",
       "  'Data',\n",
       "  'Science',\n",
       "  'Analytics',\n",
       "  'team',\n",
       "  'within',\n",
       "  'our',\n",
       "  'Product',\n",
       "  'Marketing',\n",
       "  'department',\n",
       "  'Strong',\n",
       "  'working',\n",
       "  'knowledge',\n",
       "  'of',\n",
       "  'data',\n",
       "  'mining',\n",
       "  'algorithms'],\n",
       " ['Hadoop',\n",
       "  'in',\n",
       "  'big',\n",
       "  'data',\n",
       "  'and',\n",
       "  'advanced',\n",
       "  'analytics',\n",
       "  'Develop',\n",
       "  'powerful',\n",
       "  'business',\n",
       "  'insights',\n",
       "  'from',\n",
       "  'social',\n",
       "  'marketing',\n",
       "  'and',\n",
       "  'industrial',\n",
       "  'data',\n",
       "  'using',\n",
       "  'advanced'],\n",
       " ['Minimum',\n",
       "  '8',\n",
       "  'years',\n",
       "  'of',\n",
       "  'continuous',\n",
       "  'and',\n",
       "  'latest',\n",
       "  'experience',\n",
       "  'in',\n",
       "  'data',\n",
       "  'analytics',\n",
       "  'management',\n",
       "  'statistical',\n",
       "  'analysis',\n",
       "  'quantitative',\n",
       "  'analytics',\n",
       "  'andor',\n",
       "  'forecastingpredictive'],\n",
       " ['Evaluate',\n",
       "  'the',\n",
       "  'stability',\n",
       "  'data',\n",
       "  'and',\n",
       "  'trends',\n",
       "  'We',\n",
       "  'are',\n",
       "  'looking',\n",
       "  'for',\n",
       "  'an',\n",
       "  'analytical',\n",
       "  'scientist',\n",
       "  'who',\n",
       "  'has',\n",
       "  'microbiology',\n",
       "  'education',\n",
       "  'background',\n",
       "  'and',\n",
       "  'has',\n",
       "  'knowledge',\n",
       "  'of'],\n",
       " ['Must',\n",
       "  'be',\n",
       "  'able',\n",
       "  'to',\n",
       "  'write',\n",
       "  'SQL',\n",
       "  'queries',\n",
       "  'and',\n",
       "  'must',\n",
       "  'have',\n",
       "  'experience',\n",
       "  'with',\n",
       "  'data',\n",
       "  'extraction',\n",
       "  'We',\n",
       "  'have',\n",
       "  'a',\n",
       "  'client',\n",
       "  'that',\n",
       "  'is',\n",
       "  'looking',\n",
       "  'for',\n",
       "  'a',\n",
       "  'data',\n",
       "  'scientist',\n",
       "  'to',\n",
       "  'add',\n",
       "  'to',\n",
       "  'its',\n",
       "  'team'],\n",
       " ['Leveraging',\n",
       "  'the',\n",
       "  'latest',\n",
       "  'technologies',\n",
       "  'in',\n",
       "  'big',\n",
       "  'data',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'and',\n",
       "  'data',\n",
       "  'mining',\n",
       "  'Spirent',\n",
       "  'provides',\n",
       "  'stateoftheart',\n",
       "  'software',\n",
       "  'products',\n",
       "  'for',\n",
       "  'communication',\n",
       "  'service'],\n",
       " ['Support',\n",
       "  'the',\n",
       "  'Director',\n",
       "  'Data',\n",
       "  'Science',\n",
       "  'and',\n",
       "  'Evaluation',\n",
       "  'Research',\n",
       "  'and',\n",
       "  'the',\n",
       "  'SVP',\n",
       "  'of',\n",
       "  'Public',\n",
       "  'Health',\n",
       "  'and',\n",
       "  'Inclusion',\n",
       "  'in',\n",
       "  'developing',\n",
       "  'and',\n",
       "  'implementing',\n",
       "  'Autism',\n",
       "  'Speaks',\n",
       "  '’',\n",
       "  'public'],\n",
       " ['Stay',\n",
       "  'current',\n",
       "  'on',\n",
       "  'new',\n",
       "  'trends',\n",
       "  'in',\n",
       "  'revenue',\n",
       "  'management',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'and',\n",
       "  'advanced',\n",
       "  'analytics',\n",
       "  'through',\n",
       "  'reviews',\n",
       "  'of',\n",
       "  'academic',\n",
       "  'and',\n",
       "  'practitioner',\n",
       "  'literature'],\n",
       " ['We',\n",
       "  'are',\n",
       "  'looking',\n",
       "  'for',\n",
       "  'an',\n",
       "  'exceptional',\n",
       "  'data',\n",
       "  'scientists',\n",
       "  'with',\n",
       "  'a',\n",
       "  'passion',\n",
       "  'for',\n",
       "  'using',\n",
       "  'data',\n",
       "  'to',\n",
       "  'discover',\n",
       "  'insights',\n",
       "  'and',\n",
       "  'utilize',\n",
       "  'them',\n",
       "  'to',\n",
       "  'drive',\n",
       "  'decisionmaking'],\n",
       " ['Advanced',\n",
       "  'Analytics',\n",
       "  'Data',\n",
       "  'Scientists',\n",
       "  'Data',\n",
       "  'Scientist',\n",
       "  'II',\n",
       "  'Design',\n",
       "  'deploy',\n",
       "  'and',\n",
       "  'maintain',\n",
       "  'statistical',\n",
       "  'predictive',\n",
       "  'and',\n",
       "  'data',\n",
       "  'mining',\n",
       "  'models',\n",
       "  'to',\n",
       "  'translate',\n",
       "  'data',\n",
       "  'into'],\n",
       " ['This',\n",
       "  'group',\n",
       "  'is',\n",
       "  'responsible',\n",
       "  'for',\n",
       "  'the',\n",
       "  'data',\n",
       "  'ecosystem',\n",
       "  'that',\n",
       "  'runs',\n",
       "  'our',\n",
       "  'businesses',\n",
       "  'with',\n",
       "  'teams',\n",
       "  'that',\n",
       "  'ensure',\n",
       "  'our',\n",
       "  'data',\n",
       "  'is',\n",
       "  'accurate',\n",
       "  'timely',\n",
       "  'and',\n",
       "  'has',\n",
       "  'the',\n",
       "  'proper',\n",
       "  'risk',\n",
       "  'controls'],\n",
       " ['Preparation',\n",
       "  'clinical',\n",
       "  'pharmacology',\n",
       "  'data',\n",
       "  'analysis',\n",
       "  'plans',\n",
       "  'tables',\n",
       "  'figures',\n",
       "  'and',\n",
       "  'listings',\n",
       "  'for',\n",
       "  'inclusion',\n",
       "  'in',\n",
       "  'clinical',\n",
       "  'reports'],\n",
       " ['HR',\n",
       "  'Data',\n",
       "  'Analytics',\n",
       "  'team',\n",
       "  'seeks',\n",
       "  'an',\n",
       "  'expert',\n",
       "  'in',\n",
       "  'data',\n",
       "  'analysis',\n",
       "  'including',\n",
       "  'data',\n",
       "  'structuring',\n",
       "  'mining',\n",
       "  'modeling',\n",
       "  'and',\n",
       "  'visualization',\n",
       "  'with',\n",
       "  'strong',\n",
       "  'project',\n",
       "  'management'],\n",
       " ['As',\n",
       "  'a',\n",
       "  'Senior',\n",
       "  'Data',\n",
       "  'Scientist',\n",
       "  'you',\n",
       "  '’',\n",
       "  'll',\n",
       "  'lead',\n",
       "  'projects',\n",
       "  'that',\n",
       "  'develop',\n",
       "  'and',\n",
       "  'perform',\n",
       "  'complex',\n",
       "  'analyses',\n",
       "  'using',\n",
       "  'Big',\n",
       "  'Data',\n",
       "  'technologies'],\n",
       " ['Train',\n",
       "  'subject',\n",
       "  'matter',\n",
       "  'experts',\n",
       "  'in',\n",
       "  'basic',\n",
       "  'data',\n",
       "  'science',\n",
       "  'skills',\n",
       "  'and',\n",
       "  'increase',\n",
       "  'organizational',\n",
       "  'awareness',\n",
       "  'about',\n",
       "  'data',\n",
       "  'analytics',\n",
       "  'through',\n",
       "  'engagement',\n",
       "  'programs'],\n",
       " ['Strong',\n",
       "  'health',\n",
       "  'care',\n",
       "  'data',\n",
       "  'knowledge',\n",
       "  'medical',\n",
       "  'claims',\n",
       "  'data',\n",
       "  'clinical',\n",
       "  'data',\n",
       "  'pharmacy',\n",
       "  'data',\n",
       "  'and',\n",
       "  'eligibility',\n",
       "  'data',\n",
       "  'preferred'],\n",
       " ['Data',\n",
       "  'scientists',\n",
       "  'lead',\n",
       "  'data',\n",
       "  'processing',\n",
       "  'and',\n",
       "  'analysis',\n",
       "  'tasks',\n",
       "  'such',\n",
       "  'as',\n",
       "  'monitoring',\n",
       "  'data',\n",
       "  'quality',\n",
       "  'developing',\n",
       "  'documentation',\n",
       "  'applying',\n",
       "  'statistical',\n",
       "  'and',\n",
       "  'data',\n",
       "  'science'],\n",
       " ['Scientific',\n",
       "  'engineering',\n",
       "  'and',\n",
       "  'practical',\n",
       "  'knowledge',\n",
       "  'of',\n",
       "  'techniques',\n",
       "  'and',\n",
       "  'procedures',\n",
       "  'applied',\n",
       "  'to',\n",
       "  'environmental',\n",
       "  'compliance',\n",
       "  'andor',\n",
       "  'waste',\n",
       "  'management',\n",
       "  'applicable',\n",
       "  'to',\n",
       "  'a',\n",
       "  'wide'],\n",
       " ['Maintains',\n",
       "  'scientific',\n",
       "  'curiosity',\n",
       "  'rigor',\n",
       "  'and',\n",
       "  'documentation',\n",
       "  'Competency',\n",
       "  'to',\n",
       "  'manage',\n",
       "  'moderate',\n",
       "  'level',\n",
       "  'of',\n",
       "  'technical',\n",
       "  'complexity',\n",
       "  'execute',\n",
       "  'rapid',\n",
       "  'and',\n",
       "  'iterative',\n",
       "  'development'],\n",
       " ['for',\n",
       "  'data',\n",
       "  'analysis',\n",
       "  'testing',\n",
       "  'purpose',\n",
       "  'Job',\n",
       "  'Type',\n",
       "  'Temporary',\n",
       "  'Salary',\n",
       "  '1000',\n",
       "  'to',\n",
       "  '1100'],\n",
       " ['Professional',\n",
       "  'experience',\n",
       "  'applying',\n",
       "  'advanced',\n",
       "  'analytics',\n",
       "  'and',\n",
       "  'data',\n",
       "  'mining',\n",
       "  'techniques',\n",
       "  'to',\n",
       "  'enable',\n",
       "  'decision',\n",
       "  'support',\n",
       "  'systems',\n",
       "  'and',\n",
       "  'customer',\n",
       "  'strategies'],\n",
       " ['Scientific',\n",
       "  'engineering',\n",
       "  'and',\n",
       "  'practical',\n",
       "  'knowledge',\n",
       "  'of',\n",
       "  'techniques',\n",
       "  'and',\n",
       "  'procedures',\n",
       "  'applied',\n",
       "  'to',\n",
       "  'environmental',\n",
       "  'compliance',\n",
       "  'andor',\n",
       "  'waste',\n",
       "  'management',\n",
       "  'applicable',\n",
       "  'to',\n",
       "  'a',\n",
       "  'wide'],\n",
       " ['Peer',\n",
       "  'Review',\n",
       "  'of',\n",
       "  'Data',\n",
       "  'of',\n",
       "  'other',\n",
       "  'scientist',\n",
       "  'and',\n",
       "  'sterility',\n",
       "  'technicians',\n",
       "  'Generating',\n",
       "  'Quality',\n",
       "  'Data',\n",
       "  'Trend',\n",
       "  'Reports',\n",
       "  'Working',\n",
       "  'knowledge',\n",
       "  'of',\n",
       "  'data',\n",
       "  'collection',\n",
       "  'andor',\n",
       "  'spreadsheet'],\n",
       " ['Strong',\n",
       "  'health',\n",
       "  'care',\n",
       "  'data',\n",
       "  'knowledge',\n",
       "  'medical',\n",
       "  'claims',\n",
       "  'data',\n",
       "  'clinical',\n",
       "  'data',\n",
       "  'pharmacy',\n",
       "  'data',\n",
       "  'and',\n",
       "  'eligibility',\n",
       "  'data',\n",
       "  'preferred'],\n",
       " ['Ensure',\n",
       "  'complete',\n",
       "  'accuracy',\n",
       "  'appropriate',\n",
       "  'and',\n",
       "  'consistent',\n",
       "  'grammar',\n",
       "  'spelling',\n",
       "  'and',\n",
       "  'punctuation',\n",
       "  'on',\n",
       "  'all',\n",
       "  'reports',\n",
       "  'and',\n",
       "  'data',\n",
       "  'collections'],\n",
       " ['The',\n",
       "  'role',\n",
       "  'Senior',\n",
       "  'Data',\n",
       "  'Scientist',\n",
       "  'will',\n",
       "  'be',\n",
       "  'responsible',\n",
       "  'for',\n",
       "  'organizing',\n",
       "  'mining',\n",
       "  'and',\n",
       "  'visualizing',\n",
       "  'complex',\n",
       "  'RD',\n",
       "  'data',\n",
       "  'to',\n",
       "  'deliver',\n",
       "  'new',\n",
       "  'insights',\n",
       "  'to',\n",
       "  'enable',\n",
       "  'rapid',\n",
       "  'high',\n",
       "  'quality'],\n",
       " ['Candidate',\n",
       "  'MUST',\n",
       "  'live',\n",
       "  'in',\n",
       "  'NJ',\n",
       "  'Philadelphia',\n",
       "  'PA',\n",
       "  'area',\n",
       "  'or',\n",
       "  'NYC',\n",
       "  'area',\n",
       "  'Position',\n",
       "  'will',\n",
       "  'include',\n",
       "  'assisting',\n",
       "  'with',\n",
       "  'the',\n",
       "  'research',\n",
       "  'data',\n",
       "  'collection',\n",
       "  'and',\n",
       "  'reporting',\n",
       "  'for',\n",
       "  'Phase',\n",
       "  'I'],\n",
       " ['Must',\n",
       "  'be',\n",
       "  'agile',\n",
       "  'to',\n",
       "  'grow',\n",
       "  'in',\n",
       "  'new',\n",
       "  'directions',\n",
       "  'acquire',\n",
       "  'new',\n",
       "  'skills',\n",
       "  'and',\n",
       "  'work',\n",
       "  'with',\n",
       "  'a',\n",
       "  'team',\n",
       "  'of',\n",
       "  'scientists',\n",
       "  'and',\n",
       "  'practitioners',\n",
       "  'from',\n",
       "  'different',\n",
       "  'functional',\n",
       "  'areas',\n",
       "  'to',\n",
       "  'solve'],\n",
       " ['Strong',\n",
       "  'proven',\n",
       "  'understanding',\n",
       "  'of',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'methods',\n",
       "  'and',\n",
       "  'applied',\n",
       "  'statistical',\n",
       "  'packages',\n",
       "  'as',\n",
       "  'applied',\n",
       "  'to',\n",
       "  'data',\n",
       "  'analysis',\n",
       "  'within',\n",
       "  'open',\n",
       "  'source',\n",
       "  'scripting',\n",
       "  'languages',\n",
       "  'eg'],\n",
       " ['Be',\n",
       "  'a',\n",
       "  'subject',\n",
       "  'matter',\n",
       "  'expert',\n",
       "  'on',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'and',\n",
       "  'predictive',\n",
       "  'modeling',\n",
       "  'and',\n",
       "  'a',\n",
       "  'mentor',\n",
       "  'to',\n",
       "  'junior',\n",
       "  'data',\n",
       "  'scientists'],\n",
       " ['Communication',\n",
       "  'and',\n",
       "  'presentation',\n",
       "  'to',\n",
       "  'external',\n",
       "  'clients',\n",
       "  'with',\n",
       "  'relevance',\n",
       "  'to',\n",
       "  'the',\n",
       "  'market',\n",
       "  'and',\n",
       "  'consumer',\n",
       "  'insights',\n",
       "  'Consistently',\n",
       "  'meets',\n",
       "  'agreed',\n",
       "  'upon',\n",
       "  'project',\n",
       "  'objectives'],\n",
       " ['Leveraging',\n",
       "  'your',\n",
       "  'educational',\n",
       "  'background',\n",
       "  'in',\n",
       "  'Science',\n",
       "  'Mathematics',\n",
       "  'Statistics',\n",
       "  'Computer',\n",
       "  'Science',\n",
       "  'Data',\n",
       "  'Science',\n",
       "  'or',\n",
       "  'a',\n",
       "  'related',\n",
       "  'discipline',\n",
       "  'along',\n",
       "  'with',\n",
       "  'your',\n",
       "  'relevant']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize_jobs(jobs):\n",
    "    # remove punctuation\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    jobs = [j.translate(table) for j in jobs]\n",
    "    # tokenize words\n",
    "    return [word_tokenize(j) for j in jobs]\n",
    "\n",
    "tokens = tokenize_jobs(listings)                      \n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Implement field and office data collection efforts data validation and data evaluation Process data and oversee the development of map figures data tables',\n",
       " 'Previous internship or relevant work experiences in scripting software development or data analytics In Global Data were responsible for delivering this',\n",
       " 'Junior Research Scientist At Rocky Mountain Scientific Laboratory we associate peace with strength courage and action',\n",
       " 'Candidate MUST live in NJ Philadelphia PA area or NYC area Position will include assisting with the research data collection and reporting for Phase I',\n",
       " 'Communication and presentation to external clients with relevance to the market and consumer insights Consistently meets agreed upon project objectives',\n",
       " 'Leveraging your educational background in Science Mathematics Statistics Computer Science Data Science or a related discipline along with your relevant',\n",
       " 'Ensure complete accuracy appropriate and consistent grammar spelling and punctuation on all reports and data collections',\n",
       " 'Proficient with the use of advanced statistical analysis software and applications SAS R SQL programming etc',\n",
       " 'The Data Scientist AssociateQlik Sense Developer role is responsible for modeling complex Institute problems discovering Institute insights and identifying',\n",
       " 'Data scientists must be able to discuss their research in any level of detail with their peers and with appropriate calibration to stakeholders in small and',\n",
       " 'Experience with one or more statistical or machine learning software such as R Python Background in applied statistical modeling on large experimental or',\n",
       " 'Machine Learning Engineer will be responsible for advocating educating and ensuring that machine learning ML teams across the enterprise are following best',\n",
       " 'Design develop test and document predictive classifier and deep learning machine learning AI models Some exposure to SQL server Machine Learning technics',\n",
       " 'Performs data analytics specifically data cleanup data processing predictive modeling chemometric statistical modeling and analysis multivariate data',\n",
       " 'Proficient with the use of advanced statistical analysis software and applications SAS R SQL programming etc',\n",
       " 'Develop and implement machine learning and optimization algorithms across multiple platforms to create scalable solutions with actionable insights from complex',\n",
       " 'Minimum of 2 years experience applying machine learning algorithms and data mining approaches in an applied setting is required',\n",
       " 'Data Curation Scientists are expected to perform analyses that require a highlevel understanding of the biomedical scientific literature and experimental',\n",
       " 'Manages full data portfolio of spend area working with the various spend area data owners ensuring data accuracy and validity',\n",
       " 'Ensures maintenance of continuous cGMP compliance in day to day Stability Operations by themselves and others below their level such as Associates Scientists',\n",
       " 'The Data Scientist role is responsible for designing and implementing analytical tools and predictive models based on that intelligence creating efficiencies',\n",
       " 'Data Analytics Machine Learning or equivalent experience This position is for a Data Scientist who can think strategically and intuitively about uses of data',\n",
       " 'Be a subject matter expert on machine learning and predictive modeling and a mentor to junior data scientists',\n",
       " 'Work with data architects to ensure that Big Data solutions are aligned with companywide technology directions',\n",
       " 'New Jersey ’ s academic health center Rutgers Biomedical and Health Sciences RBHS takes an integrated approach to educating students providing clinical care',\n",
       " 'Strong predictive data modeling experience is required with proven application in applying Decision Trees Regression analysis Neural Networks Clustering and',\n",
       " 'The Data Scientist will be part of the Data Science Analytics team within our Product Marketing department Strong working knowledge of data mining algorithms',\n",
       " 'Hadoop in big data and advanced analytics Develop powerful business insights from social marketing and industrial data using advanced',\n",
       " 'Minimum 8 years of continuous and latest experience in data analytics management statistical analysis quantitative analytics andor forecastingpredictive',\n",
       " 'Evaluate the stability data and trends We are looking for an analytical scientist who has microbiology education background and has knowledge of',\n",
       " 'Must be able to write SQL queries and must have experience with data extraction We have a client that is looking for a data scientist to add to its team',\n",
       " 'Leveraging the latest technologies in big data machine learning and data mining Spirent provides stateoftheart software products for communication service',\n",
       " 'Support the Director Data Science and Evaluation Research and the SVP of Public Health and Inclusion in developing and implementing Autism Speaks ’ public',\n",
       " 'Stay current on new trends in revenue management machine learning and advanced analytics through reviews of academic and practitioner literature',\n",
       " 'We are looking for an exceptional data scientists with a passion for using data to discover insights and utilize them to drive decisionmaking',\n",
       " 'Advanced Analytics Data Scientists Data Scientist II Design deploy and maintain statistical predictive and data mining models to translate data into',\n",
       " 'This group is responsible for the data ecosystem that runs our businesses with teams that ensure our data is accurate timely and has the proper risk controls',\n",
       " 'Preparation clinical pharmacology data analysis plans tables figures and listings for inclusion in clinical reports',\n",
       " 'HR Data Analytics team seeks an expert in data analysis including data structuring mining modeling and visualization with strong project management',\n",
       " 'As a Senior Data Scientist you ’ ll lead projects that develop and perform complex analyses using Big Data technologies',\n",
       " 'Train subject matter experts in basic data science skills and increase organizational awareness about data analytics through engagement programs',\n",
       " 'Strong health care data knowledge medical claims data clinical data pharmacy data and eligibility data preferred',\n",
       " 'Data scientists lead data processing and analysis tasks such as monitoring data quality developing documentation applying statistical and data science',\n",
       " 'Scientific engineering and practical knowledge of techniques and procedures applied to environmental compliance andor waste management applicable to a wide',\n",
       " 'Maintains scientific curiosity rigor and documentation Competency to manage moderate level of technical complexity execute rapid and iterative development',\n",
       " 'for data analysis testing purpose Job Type Temporary Salary 1000 to 1100',\n",
       " 'Professional experience applying advanced analytics and data mining techniques to enable decision support systems and customer strategies',\n",
       " 'Scientific engineering and practical knowledge of techniques and procedures applied to environmental compliance andor waste management applicable to a wide',\n",
       " 'Peer Review of Data of other scientist and sterility technicians Generating Quality Data Trend Reports Working knowledge of data collection andor spreadsheet',\n",
       " 'Strong health care data knowledge medical claims data clinical data pharmacy data and eligibility data preferred',\n",
       " 'Ensure complete accuracy appropriate and consistent grammar spelling and punctuation on all reports and data collections',\n",
       " 'The role Senior Data Scientist will be responsible for organizing mining and visualizing complex RD data to deliver new insights to enable rapid high quality',\n",
       " 'Candidate MUST live in NJ Philadelphia PA area or NYC area Position will include assisting with the research data collection and reporting for Phase I',\n",
       " 'Must be agile to grow in new directions acquire new skills and work with a team of scientists and practitioners from different functional areas to solve',\n",
       " 'Strong proven understanding of machine learning methods and applied statistical packages as applied to data analysis within open source scripting languages eg',\n",
       " 'Be a subject matter expert on machine learning and predictive modeling and a mentor to junior data scientists',\n",
       " 'Communication and presentation to external clients with relevance to the market and consumer insights Consistently meets agreed upon project objectives',\n",
       " 'Leveraging your educational background in Science Mathematics Statistics Computer Science Data Science or a related discipline along with your relevant']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cells = [' '.join(x) for x in tokens]\n",
    "cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Implement field and office data collection eff...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Previous internship or relevant work experienc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Junior Research Scientist At Rocky Mountain Sc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Candidate MUST live in NJ Philadelphia PA area...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Communication and presentation to external cli...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Summary\n",
       "0  Implement field and office data collection eff...\n",
       "1  Previous internship or relevant work experienc...\n",
       "2  Junior Research Scientist At Rocky Mountain Sc...\n",
       "3  Candidate MUST live in NJ Philadelphia PA area...\n",
       "4  Communication and presentation to external cli..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "description = pd.DataFrame({'Summary': cells})\n",
    "description.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5C4xFZNtX1m2"
   },
   "source": [
    "## 2) Use NLTK to tokenize / clean the listings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dhUHuMr-X-II"
   },
   "outputs": [],
   "source": [
    "##### Your Code Here #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-lgCZNL_YycP"
   },
   "source": [
    "# 3) Use Scikit-Learn's CountVectorizer to get word counts for each listing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X2PZ8Pj_YxcF"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1000</th>\n",
       "      <th>1100</th>\n",
       "      <th>able</th>\n",
       "      <th>academic</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>accurate</th>\n",
       "      <th>acquire</th>\n",
       "      <th>action</th>\n",
       "      <th>actionable</th>\n",
       "      <th>add</th>\n",
       "      <th>...</th>\n",
       "      <th>validity</th>\n",
       "      <th>various</th>\n",
       "      <th>visualization</th>\n",
       "      <th>visualizing</th>\n",
       "      <th>waste</th>\n",
       "      <th>wide</th>\n",
       "      <th>work</th>\n",
       "      <th>working</th>\n",
       "      <th>write</th>\n",
       "      <th>years</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>58 rows × 381 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    1000  1100  able  academic  accuracy  accurate  acquire  action  \\\n",
       "0      0     0     0         0         0         0        0       0   \n",
       "1      0     0     0         0         0         0        0       0   \n",
       "2      0     0     0         0         0         0        0       1   \n",
       "3      0     0     0         0         0         0        0       0   \n",
       "4      0     0     0         0         0         0        0       0   \n",
       "5      0     0     0         0         0         0        0       0   \n",
       "6      0     0     0         0         1         0        0       0   \n",
       "7      0     0     0         0         0         0        0       0   \n",
       "8      0     0     0         0         0         0        0       0   \n",
       "9      0     0     1         0         0         0        0       0   \n",
       "10     0     0     0         0         0         0        0       0   \n",
       "11     0     0     0         0         0         0        0       0   \n",
       "12     0     0     0         0         0         0        0       0   \n",
       "13     0     0     0         0         0         0        0       0   \n",
       "14     0     0     0         0         0         0        0       0   \n",
       "15     0     0     0         0         0         0        0       0   \n",
       "16     0     0     0         0         0         0        0       0   \n",
       "17     0     0     0         0         0         0        0       0   \n",
       "18     0     0     0         0         1         0        0       0   \n",
       "19     0     0     0         0         0         0        0       0   \n",
       "20     0     0     0         0         0         0        0       0   \n",
       "21     0     0     0         0         0         0        0       0   \n",
       "22     0     0     0         0         0         0        0       0   \n",
       "23     0     0     0         0         0         0        0       0   \n",
       "24     0     0     0         1         0         0        0       0   \n",
       "25     0     0     0         0         0         0        0       0   \n",
       "26     0     0     0         0         0         0        0       0   \n",
       "27     0     0     0         0         0         0        0       0   \n",
       "28     0     0     0         0         0         0        0       0   \n",
       "29     0     0     0         0         0         0        0       0   \n",
       "30     0     0     1         0         0         0        0       0   \n",
       "31     0     0     0         0         0         0        0       0   \n",
       "32     0     0     0         0         0         0        0       0   \n",
       "33     0     0     0         1         0         0        0       0   \n",
       "34     0     0     0         0         0         0        0       0   \n",
       "35     0     0     0         0         0         0        0       0   \n",
       "36     0     0     0         0         0         1        0       0   \n",
       "37     0     0     0         0         0         0        0       0   \n",
       "38     0     0     0         0         0         0        0       0   \n",
       "39     0     0     0         0         0         0        0       0   \n",
       "40     0     0     0         0         0         0        0       0   \n",
       "41     0     0     0         0         0         0        0       0   \n",
       "42     0     0     0         0         0         0        0       0   \n",
       "43     0     0     0         0         0         0        0       0   \n",
       "44     0     0     0         0         0         0        0       0   \n",
       "45     1     1     0         0         0         0        0       0   \n",
       "46     0     0     0         0         0         0        0       0   \n",
       "47     0     0     0         0         0         0        0       0   \n",
       "48     0     0     0         0         0         0        0       0   \n",
       "49     0     0     0         0         0         0        0       0   \n",
       "50     0     0     0         0         1         0        0       0   \n",
       "51     0     0     0         0         0         0        0       0   \n",
       "52     0     0     0         0         0         0        0       0   \n",
       "53     0     0     0         0         0         0        1       0   \n",
       "54     0     0     0         0         0         0        0       0   \n",
       "55     0     0     0         0         0         0        0       0   \n",
       "56     0     0     0         0         0         0        0       0   \n",
       "57     0     0     0         0         0         0        0       0   \n",
       "\n",
       "    actionable  add  ...  validity  various  visualization  visualizing  \\\n",
       "0            0    0  ...         0        0              0            0   \n",
       "1            0    0  ...         0        0              0            0   \n",
       "2            0    0  ...         0        0              0            0   \n",
       "3            0    0  ...         0        0              0            0   \n",
       "4            0    0  ...         0        0              0            0   \n",
       "5            0    0  ...         0        0              0            0   \n",
       "6            0    0  ...         0        0              0            0   \n",
       "7            0    0  ...         0        0              0            0   \n",
       "8            0    0  ...         0        0              0            0   \n",
       "9            0    0  ...         0        0              0            0   \n",
       "10           0    0  ...         0        0              0            0   \n",
       "11           0    0  ...         0        0              0            0   \n",
       "12           0    0  ...         0        0              0            0   \n",
       "13           0    0  ...         0        0              0            0   \n",
       "14           0    0  ...         0        0              0            0   \n",
       "15           1    0  ...         0        0              0            0   \n",
       "16           0    0  ...         0        0              0            0   \n",
       "17           0    0  ...         0        0              0            0   \n",
       "18           0    0  ...         1        1              0            0   \n",
       "19           0    0  ...         0        0              0            0   \n",
       "20           0    0  ...         0        0              0            0   \n",
       "21           0    0  ...         0        0              0            0   \n",
       "22           0    0  ...         0        0              0            0   \n",
       "23           0    0  ...         0        0              0            0   \n",
       "24           0    0  ...         0        0              0            0   \n",
       "25           0    0  ...         0        0              0            0   \n",
       "26           0    0  ...         0        0              0            0   \n",
       "27           0    0  ...         0        0              0            0   \n",
       "28           0    0  ...         0        0              0            0   \n",
       "29           0    0  ...         0        0              0            0   \n",
       "30           0    1  ...         0        0              0            0   \n",
       "31           0    0  ...         0        0              0            0   \n",
       "32           0    0  ...         0        0              0            0   \n",
       "33           0    0  ...         0        0              0            0   \n",
       "34           0    0  ...         0        0              0            0   \n",
       "35           0    0  ...         0        0              0            0   \n",
       "36           0    0  ...         0        0              0            0   \n",
       "37           0    0  ...         0        0              0            0   \n",
       "38           0    0  ...         0        0              1            0   \n",
       "39           0    0  ...         0        0              0            0   \n",
       "40           0    0  ...         0        0              0            0   \n",
       "41           0    0  ...         0        0              0            0   \n",
       "42           0    0  ...         0        0              0            0   \n",
       "43           0    0  ...         0        0              0            0   \n",
       "44           0    0  ...         0        0              0            0   \n",
       "45           0    0  ...         0        0              0            0   \n",
       "46           0    0  ...         0        0              0            0   \n",
       "47           0    0  ...         0        0              0            0   \n",
       "48           0    0  ...         0        0              0            0   \n",
       "49           0    0  ...         0        0              0            0   \n",
       "50           0    0  ...         0        0              0            0   \n",
       "51           0    0  ...         0        0              0            1   \n",
       "52           0    0  ...         0        0              0            0   \n",
       "53           0    0  ...         0        0              0            0   \n",
       "54           0    0  ...         0        0              0            0   \n",
       "55           0    0  ...         0        0              0            0   \n",
       "56           0    0  ...         0        0              0            0   \n",
       "57           0    0  ...         0        0              0            0   \n",
       "\n",
       "    waste  wide  work  working  write  years  \n",
       "0       0     0     0        0      0      0  \n",
       "1       0     0     1        0      0      0  \n",
       "2       0     0     0        0      0      0  \n",
       "3       0     0     0        0      0      0  \n",
       "4       0     0     0        0      0      0  \n",
       "5       0     0     0        0      0      0  \n",
       "6       0     0     0        0      0      0  \n",
       "7       0     0     0        0      0      0  \n",
       "8       0     0     0        0      0      0  \n",
       "9       0     0     0        0      0      0  \n",
       "10      0     0     0        0      0      0  \n",
       "11      0     0     0        0      0      0  \n",
       "12      0     0     0        0      0      0  \n",
       "13      0     0     0        0      0      0  \n",
       "14      0     0     0        0      0      0  \n",
       "15      0     0     0        0      0      0  \n",
       "16      0     0     0        0      0      1  \n",
       "17      0     0     0        0      0      0  \n",
       "18      0     0     0        1      0      0  \n",
       "19      0     0     0        0      0      0  \n",
       "20      0     0     0        0      0      0  \n",
       "21      0     0     0        0      0      0  \n",
       "22      0     0     0        0      0      0  \n",
       "23      0     0     1        0      0      0  \n",
       "24      0     0     0        0      0      0  \n",
       "25      0     0     0        0      0      0  \n",
       "26      0     0     0        1      0      0  \n",
       "27      0     0     0        0      0      0  \n",
       "28      0     0     0        0      0      1  \n",
       "29      0     0     0        0      0      0  \n",
       "30      0     0     0        0      1      0  \n",
       "31      0     0     0        0      0      0  \n",
       "32      0     0     0        0      0      0  \n",
       "33      0     0     0        0      0      0  \n",
       "34      0     0     0        0      0      0  \n",
       "35      0     0     0        0      0      0  \n",
       "36      0     0     0        0      0      0  \n",
       "37      0     0     0        0      0      0  \n",
       "38      0     0     0        0      0      0  \n",
       "39      0     0     0        0      0      0  \n",
       "40      0     0     0        0      0      0  \n",
       "41      0     0     0        0      0      0  \n",
       "42      0     0     0        0      0      0  \n",
       "43      1     1     0        0      0      0  \n",
       "44      0     0     0        0      0      0  \n",
       "45      0     0     0        0      0      0  \n",
       "46      0     0     0        0      0      0  \n",
       "47      1     1     0        0      0      0  \n",
       "48      0     0     0        1      0      0  \n",
       "49      0     0     0        0      0      0  \n",
       "50      0     0     0        0      0      0  \n",
       "51      0     0     0        0      0      0  \n",
       "52      0     0     0        0      0      0  \n",
       "53      0     0     1        0      0      0  \n",
       "54      0     0     0        0      0      0  \n",
       "55      0     0     0        0      0      0  \n",
       "56      0     0     0        0      0      0  \n",
       "57      0     0     0        0      0      0  \n",
       "\n",
       "[58 rows x 381 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# create the transform\n",
    "vectorizer = CountVectorizer(lowercase=True, stop_words='english')\n",
    "# tokenize and build vocab\n",
    "vectorizer.fit(cells)\n",
    "# Create a Vocabulary\n",
    "# The vocabulary establishes all of the possible words that we might use.\n",
    "counted = (vectorizer.vocabulary_)\n",
    "# counted\n",
    "# The vocabulary dictionary does not represent the counts of words!!\n",
    "counts = vectorizer.transform(cells)\n",
    "features = vectorizer.get_feature_names()\n",
    "values = counts.toarray()\n",
    "df = pd.DataFrame(values, columns=features)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zo1iH_UeY7_n"
   },
   "source": [
    "# 4) Visualize the most common word counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M5LB00uyZKV5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bwFsTqrVZMYi"
   },
   "source": [
    " # 5) Use Scikit-Learn's tfidfVectorizer to get a TF-IDF feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-gx2gZCbl5Np"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(58, 20)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>analysis</th>\n",
       "      <th>analytics</th>\n",
       "      <th>and</th>\n",
       "      <th>data</th>\n",
       "      <th>for</th>\n",
       "      <th>in</th>\n",
       "      <th>is</th>\n",
       "      <th>learning</th>\n",
       "      <th>machine</th>\n",
       "      <th>modeling</th>\n",
       "      <th>of</th>\n",
       "      <th>or</th>\n",
       "      <th>science</th>\n",
       "      <th>scientist</th>\n",
       "      <th>scientists</th>\n",
       "      <th>statistical</th>\n",
       "      <th>that</th>\n",
       "      <th>the</th>\n",
       "      <th>to</th>\n",
       "      <th>with</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.424291</td>\n",
       "      <td>0.826473</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.255289</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.267857</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.305004</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.309715</td>\n",
       "      <td>0.271160</td>\n",
       "      <td>0.489818</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.705408</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.323474</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.744609</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.583886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.204545</td>\n",
       "      <td>0.239058</td>\n",
       "      <td>0.418599</td>\n",
       "      <td>0.378074</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.544480</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.387389</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.369213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.419428</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397179</td>\n",
       "      <td>0.72321</td>\n",
       "      <td>0.378544</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   analysis  analytics       and      data       for        in   is  learning  \\\n",
       "0       0.0   0.000000  0.424291  0.826473  0.000000  0.000000  0.0       0.0   \n",
       "1       0.0   0.305004  0.000000  0.309715  0.271160  0.489818  0.0       0.0   \n",
       "2       0.0   0.000000  0.323474  0.000000  0.000000  0.000000  0.0       0.0   \n",
       "3       0.0   0.000000  0.204545  0.239058  0.418599  0.378074  0.0       0.0   \n",
       "4       0.0   0.000000  0.419428  0.000000  0.000000  0.000000  0.0       0.0   \n",
       "\n",
       "   machine  modeling        of        or  science  scientist  scientists  \\\n",
       "0      0.0       0.0  0.255289  0.000000      0.0   0.000000         0.0   \n",
       "1      0.0       0.0  0.000000  0.705408      0.0   0.000000         0.0   \n",
       "2      0.0       0.0  0.000000  0.000000      0.0   0.744609         0.0   \n",
       "3      0.0       0.0  0.000000  0.544480      0.0   0.000000         0.0   \n",
       "4      0.0       0.0  0.000000  0.000000      0.0   0.000000         0.0   \n",
       "\n",
       "   statistical  that       the       to      with  \n",
       "0          0.0   0.0  0.267857  0.00000  0.000000  \n",
       "1          0.0   0.0  0.000000  0.00000  0.000000  \n",
       "2          0.0   0.0  0.000000  0.00000  0.583886  \n",
       "3          0.0   0.0  0.387389  0.00000  0.369213  \n",
       "4          0.0   0.0  0.397179  0.72321  0.378544  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# List of document strings as text\n",
    "text = cells\n",
    "# Instantiate vectorizer object\n",
    "tfidf = TfidfVectorizer(ngram_range=(1,1), max_features=20)\n",
    "# Create a vocabulary and get word counts per document\n",
    "feature_matrix = tfidf.fit_transform(text)\n",
    "# Print word counts\n",
    "# print(feature_matrix.toarray())\n",
    "\n",
    "# Get feature names to use as dataframe column headers\n",
    "feature_names = tfidf.get_feature_names()\n",
    "\n",
    "# View Feature Matrix as DataFrame\n",
    "df1 = pd.DataFrame(feature_matrix.toarray(), columns=feature_names)\n",
    "print(df1.shape)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FiDfTWceoRkH"
   },
   "source": [
    "## Stretch Goals\n",
    "\n",
    " - Scrape Job Listings for the job title \"Data Analyst\". How do these differ from Data Scientist Job Listings\n",
    " - Try and identify requirements for experience specific technologies that are asked for in the job listings. How are those distributed among the job listings?\n",
    " - Use a clustering algorithm to cluster documents by their most important terms. Do the clusters reveal any common themes?\n",
    "  - **Hint:** K-means might not be the best algorithm for this. Do a little bit of research to see what might be good for this. Also, remember that algorithms that depend on Euclidean distance break down with high dimensional data."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LS_DS_422_BOW_Assignment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
